\documentclass{jps-cp}
\usepackage{txfonts} %Please comment out this line unless the txfonts package is availabe in your LaTeX system.
\usepackage{url}
\usepackage{multirow}
\usepackage{array, booktabs}
\usepackage{wrapfig}

\makeatletter
\newcommand{\figcaption}[1]{\def\@captype{figure}\caption{#1}}
\newcommand{\tblcaption}[1]{\def\@captype{table}\caption{#1}}

\title{New analysis method of TPC data using neural network}

\author{
  Takanobu \textsc{Doi}$^{1}$, Takahiro \textsc{Kawabata}$^{2}$, Tatsuya \textsc{Furuno}$^{3}$,
  Yuki \textsc{Fujikawa}$^{1}$, Kento \textsc{Inaba}$^{1}$, Motoki \textsc{Murata}$^{3}$,
  Shintaro \textsc{Okamoto}$^{1}$ and Akane \textsc{Sakaue}$^{1}$}

\inst{
  $^{1}$Department of Physics, Kyoto University, Kyoto, Kyoto 606-8502, Japan \\
  $^{2}$Department of Physics, Osaka University, Toyonaka, Osaka 540-0043, Japan \\
  $^{3}$Research Center for Nuclear Physics, Osaka University, Ibaraki, Osaka 567-0047, Japan }

\email{doi.takanobu.68x@st.kyoto-u.ac.jp}

\recdate{2019/8/31} % Write received date here

\abst{
  In the experiments with TPC, we can detect tracks.
  A 3-dimensional track is projected into 2-dimensional planes.
  It is necessary to analyze 2-dimensional image data from TPC.
  Conventionally, the analysis is used Hough transformation.
  This analysis requires a lot of efforts.
  These days, neural networks are attracting attention for image recognition.
  In this work, we developed new analysis method using neural networks.
  By using new method, analysis can be performed faster than the conventional method.
%
%  TPC を用いた実験では荷電粒子の飛跡を測定することができる。
%  TPC では3次元的な荷電粒子の飛跡を2次元平面に射影した画像として得られるので、
%  データの解析には画像解析を行う必要がある。
%  従来はHough 変換を用いてデータの解析を行って来たが、
%  この方法を用いた解析には多くの労力を要する。
%  近年、画像データの認識にはニューラルネットワークが注目されている。
%  本研究では、新しくニューラルネットワークを用いた解析方法の開発を行った。
%  新しく開発した手法を用いることで、従来の方法と比較して高速に解析できるようになった。
} % Write abstract here

\kword{neural networks, time projection chamber (TPC), active target, MAIKo TPC} % Write keywords here

\begin{document}
\maketitle

\section{Introduction}
\begin{wrapfigure}{r}{16zw}
  \vspace{0zw}
  \centering
  \includegraphics[clip, width=16zw]{eps/MAIKo.eps}
  \caption{This shows an overview of MAIKo TPC.}
  \label{fig:MAIKo}
  \vspace{0zw}
\end{wrapfigure}
These days, Time Projection Chamber (TPC) is widely used to detect tracks of charged particles.
We developed Mu-PIC based Active target for Inverse Kinematics . (MAIKo) TPC~\cite{MAIKo}
using Micro Pixel Chamber ($\mu$-PIC)~\cite{mupic} for unstable nuclei experiments.
Figure \ref{fig:MAIKo} shows the overview of MAIKo TPC.
Detection gas is filled in TPC.
When charged particles pass through the gas, electrons emitted.
These electrons are drifted in the direction for the readout surface(downer arrow)
by a drift electric field (upper arrow) and the tracks are detected.
%
%近年、荷電粒子の飛跡を測定する検出器としてTime Projection Chamber (TPC) が
%広く用いられている。
%我々は不安定核実験のためにMicro Pixel Chamber ($\mu$-PIC)~\cite{mupic}を用いた
%Mu-Pic based Active target for Inverse Kinematics . (MAIKo) TPC~\cite{MAIKo}を開発した。
%MAIKo の概観図を Fig. \ref{fig:MAIKo} に示す。
%TPC は検出器にガスを充填しておき、荷電粒子がガス中を通過するときに発生する
%電子をドリフト電場 (上向き矢印) により読み出し面方向 (下向き) にドリフトさせる
%ことで飛跡を検出する。
The $\mu$-PIC has 256 of anode strips and cathode strips
which are arranged orthogonally.
These strips are aligned at 400-$\rm{\mu m}$ intervals.
Anode strips are parallel to x-axis in Fig. \ref{fig:MAIKo} and %は Fig. \ref{fig:MAIKo}のx軸の方向、
cathode strips are parallel to z-axis.%は z軸の方向と平行である。
The signals induced by the drifted electrons are read out through the anode and 
cathode strips which provide the 2-dimensional position (x-axis and z-axis) 
of the particle tracks.
The vertical position (y-axis) of the tracks is determined 
from the drift time of the electrons.
The 3-dimensional tracks are reconstructed from x, y, z-coordinates.
%x, y, zの座標が決定できるので、飛跡を3次元的に再構成することが出来る。

MAIKo TPC is the active target that a detection gas is used for a target gas.
By using the active target, incident particles scatter with target particles in the detector.
It is possible to detect low energy particles in a large solid angle.
$\rm{He}$ or $\rm{H}_{2}$ that is widely used for a target gas
has low discharge resistance.
Normally, $\rm{CO}_{2}$ or iso-butane that has high discharge resistance is used for a quench gas and
mixed with a target gas.
The events that incident particles are scattered with quench gas become background events.
The elastic and inelastic alpha scattering on ${}^{10}\rm{C}$ were measured with MAIKo TPC
at Research Center for Nuclear Physics, Osaka University (RCNP).
In this experiment, $\rm{He}$ (96\%) was used as target gas and $\rm{CO}_{2}$ (4\%) was used as quench gas.
%MAIKo TPC は検出ガスを散乱の標的として用いるアクティブ標的である。
%アクティブ標的では散乱が検出器内部で起こるため、大立体角で低エネルギー粒子の測定を行うことが可能となる。
%広く標的ガスとして用いられるのは $\rm{He}$ や $\rm{H}_{2}$であるが、
%これらのガスは放電耐性が低いので、
%通常は放電耐性の高い $\rm{CO}_{2}$ やイソブタンをクエンチングガスとして
%混合させてTPC を運用する。
%このとき、クエンチングガスからの散乱は背景事象となる。
%近年、大阪大学核物理研究センター (RCNP) において、
%MAIKo TPC を用いた${}^{10}\rm{C}$と${}^{4}\rm{He}$の非弾性散乱の測定が初めて行われた。
%この実験では標的ガスである$\rm{He}$ (96\%)に、$\rm{CO}_{2}$ (4\%)をクエンチングガスとして
%混合して測定を行った。

The track of charged particle is projected into a plane that is perpendicular to anode strips (anode image) and
a plane that is perpendicular to cathode strips (cathode image).
MAIKo TPC outputs two images by one event.
$\mu$-PIC has 256 anode strips and 256 cathode strips,
and measure waveform by 1,024 samples in 100 MHz.
The resolution of an image from MAIKo TPC is 256 $\times$ 1,024.
Figures \ref{fig:true} and \ref{fig:false} are examples of measured data at RCNP.
Figure \ref{fig:true} shows the event that a incident particle scattered with $\rm{He}$ and
Fig. \ref{fig:false} shows the event that a incident particle scattered with quench gas.
%MAIKo TPC において荷電粒子の飛跡は、
%anode strip に垂直な面に射影された画像 (anode image) と
%cathode strip に垂直な面に射影された画像 (cathode image) の2つの画像として取得される。
%$\mu$-PIC の anode and cathode strips は256 本あり、
%信号波高の時間変化は100 MHz で1,024 samples 測定されるので、
%取得される画像の解像度は256 $\times$ 1,024 pixels となる。
%Figures \ref{fig:true} and \ref{fig:false} はRCNPで行われた実験で取得された
%データの一例である。
%Figure \ref{fig:true} は$\rm{He}$ガスと散乱した事象、
%Fig. \ref{fig:false} はクエンチングガスと散乱した事象である。

In a scattering experiment, it is necessary to determine the energy and emission angle of the scattering particles.
The energy is determined from the length of a track.
The emission angle is determined from open angle of the incident particle and the scattering particle.
To extract the information of tracks, there are two steps.
\begin{itemize}
\item
  Select events scattered with target and background events.
\item
  Extract the length and the emission angle from images.
\end{itemize}
%散乱実験では、散乱粒子のエネルギーと放出角度を決定する必要がある。
%散乱粒子のエネルギーは散乱粒子がガス中で停止するまでの飛跡の長さから、
%放出角度は散乱前後の粒子の飛跡から決定することが出来る。
%飛跡情報の抽出を行うためには
%\begin{itemize}
%\item 標的との散乱事象と背景事象との選別
%\item 飛跡の長さや方向などの物理的情報の抽出
%\end{itemize}
%の大きくわけて2つの解析が必要になる。

\begin{figure}
  \centering
  \begin{minipage}{0.45\columnwidth}
    \centering
    \includegraphics[clip, width=0.9\columnwidth]{eps/true.eps}
    \caption{An incident ${}^{10}\rm{C}$ scattered with ${}^{4}\rm{He}$.}
    \label{fig:true}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\columnwidth}
    \centering
    \includegraphics[clip, width=0.9\columnwidth]{eps/false.eps}
    \caption{An incident${}^{10}\rm{C}$ scattered with quench gas.}
    \label{fig:false}
  \end{minipage}
\end{figure}

There are a lot of efforts to select events and extract information of tracks.
So, we developed faster analysis method using neural networks that are attracted attention in image recognition.
%Figures \ref{fig:true} and \ref{fig:false} のような画像データに対して、
%事象の選別や飛跡情報の抽出には多くの労力が必要となる。
%そこで、我々は近年画像認識において多くの成果を出している
%ニューラルネットワークを用いることで、
%より高速な解析を行うことが出来る解析方法の開発を行った。

\section{Conventional analysis method}
Conventionally, the Hough transformation was used in order to remove background from data.
The Hough transformation is one of methods to find lines from a image.
%従来は、得られたデータから背景事象の除去を行うために、
%画像中の直線を抽出する手法の１つである
%Hough 変換を用いたアルゴリズムによって行ってきた。
In the Hough transformation, a hit pixel in the image at $(x_{i}, y_{i})$ is transformed into
a curved line in the $(\theta, r)$ parameter space (Hough space)
according to Esq. (\ref{eq:real2hough}).
\begin{equation}
  \label{eq:real2hough}
  r = x_{i}\cos\theta+y_{i}\sin\theta. 
\end{equation}
A point at $(\theta_{i}, r_{i})$ in the Hough space specify a straight line
in the image as given by Eq. (\ref{eq:hough2real}).
\begin{equation}
  \label{eq:hough2real}
  y = -\frac{x}{\tan\theta_{j}}+\frac{r_{j}}{\sin\theta_{j}}. 
\end{equation}

When the pixels in the anode or cathode image lie on a straight line,
their transformed curves intersect at one point at $(\theta_{j}, r_{j})$ in the Hough space.
Thus, the intersection point in the Hough space gives the particle track according to Eq. (\ref{eq:hough2real}).

It is possible to select the events scattered with $\rm{He}$ by using conditions of
the length, the angle, the number, and the location of tracks.
The energy and the scattering angle is determined from them.
This method using the Hough transfomation needs complicated condition branches with many parameters.
It needs too much time to tune the parameters.
%抽出した直線の長さや角度、本数、配置に対して多くの条件を課すことによって、
%$\rm{He}$との散乱事象を選別することが出来る。
%さらに、選別された事象における$\rm{He}$の飛跡の長さや角度から、
%散乱角とエネルギーを決定することが出来る。
%しかし、事象選別に必要な条件には複雑な分岐を必要とし、
%多くのパラメータを導入しなければならない。
%そのため、パラメータの最適化や画像識別に多くの時間を必要とする。

It takes about 1 day to tune the parameters using 100 CPUs.
It takes about 1 second by 1 event to process the images after the parameter tuning.
The selection ability is evaluated by 3,000 events that was judged by human eyes.
The accuracy, that is ratio of judgement correctly, is 89\%.
%パラメータの最適化には100 CPU を使用して約１日かかり、
%その後の画像識別には1 eventあたり１秒かかった。
%この手法による識別能力の評価には、画像データを人間が目で見て
%散乱事象もしくは背景事象と判断した3,000イベントを評価用データとして用いて行った。
%全事象のうち、散乱事象または背景事象の区別を正しく判断することが
%出来た事象数の割合を正解率としたとき、この従来型の解析手法では89\%の正解率であった。

\section{New analysis method}
There are problems that the conventional method needs complicated condition branches and much machine power.
We developed new method using neural networks that are recently attracting attention for image recognition.
Using neural networks, it may is possible to recognize images with not using complicated condition branches,
but considering many features at the same time.
Once a neural network trained, it is able to recognize images fast.
Using these features of neural networks, it is expected to realize higher accuracy and
faster recognition speed than the conventional method.

%従来手法では識別に複雑な分岐条件や多くの計算機パワー
%が必要になるという問題点があった。
%そこで、我々は近年注目されているニューラルネットワークを用いることで、
%これらの問題点を克服する新しい解析方法の開発を試みた。
%ニューラルネットワークを用いることで、複雑な条件分岐を導入することなく、
%直線の位置、角度などの従来の解析手法ではまとめて扱うことの難しい
%多くの特徴量を同時に考慮した画像識別が可能になるかもしれない。
%また、ニューラルネットワークは一度構築するとその後は短時間で画像識別を行うことができる。
%このようなニューラルネットワークの特徴を活かすことで、
%従来のアルゴリズムでは実現が難しかった高い精度と短い識別時間を実現することが期待される。

\vspace{-2zw}
\begin{figure}
  \centering
  \begin{minipage}{0.4\columnwidth}
    \centering
    \includegraphics[clip, width=0.9\columnwidth]{eps/event_selection.eps}
%    \caption{データの選別を行うためのニューラルネットワーク}
    \caption{This neural network selects events scattered with a target.}
    \label{fig:selection}
  \end{minipage}
  \hfill
  \begin{minipage}{0.4\columnwidth}
    \centering
    \includegraphics[clip, width=0.9\columnwidth]{eps/point_detection.eps}
%    \caption{画像から情報を抽出するためのニューラルネットワーク}
    \caption{This neural network extracts imformation of tracks from images.}
    \label{fig:extraction}
  \end{minipage}
\end{figure}

We used Convolutional Neural Network (CNN) that is useful for image recognition,
because the data from MAIKo TPC are images.
CNN is the network that has convolutional layers.
The analysis has two steps that are event selection and track extraction.
We used two networks to analyze.
Figures \ref{fig:selection} and \ref{fig:extraction} show
the network that selects events and that extracts information of tracks.
%MAIKo TPC から得られるデータが画像であるため、画像認識に有用とされる
%Convolutional Neural Network (CNN)~\cite{lenet,alexnet} を用いた。
%CNN とはネットワーク内に畳み込み層を有するネットワーク構造である。
%解析には事象の選別と飛跡情報の抽出の２つの段階があるため、
%２種類のニューラルネットワークを用いて解析を行った。
%事象の選別を行うニューラルネットワークと
%画像から飛跡情報を抽出するニューラルネットワークの構造を
%それぞれFigs. \ref{fig:selection} and \ref{fig:extraction}に示す。

We input pair of images from MAIKo TPC to the neural network for event selection and
it outputs probability of event that ${}^{10}\rm{C}$ scattered with a target.
If the probability is bigger than 50\%, the event is judged scattering with a target.
Because the anode image and cathode image has different features,
the network has two branches.
This network was trained and evaluated with the data that is judged by eye-scan.
2,700 events for training and 300 events for evaluation are used.
%事象選別のためのニュラルネットワークは、MAIKo TPC から得られる２つの画像を入力し、
%その事象が標的と散乱した事象である確率を出力する。
%出力された確率が50\%以上である場合にその事象を標的と散乱した事象であるとした。
%anode image と cathode image では飛跡が異なる特徴を持つため、
%２つの入力が別れた構造を持つネットワークを構築した。
%人間が判断したデータを用いて、学習および評価を行った。
%学習には2,700 events、評価には300 events を使用した。

We input pair of images from MAIKo TPC to the neural network for track extraction and
it outputs coordinates of points at that a incident particle scattered and at that recoil ${}^{4}\rm{He}$ stopped.
This network was trained and evaluated with the data that is determined by the conventional method.
3,012 events for training and 1,554 events for evaluation are uesd.
%飛跡情報を抽出するためのネットワークには、
%事象選別のときと同様に MAIKo TPC から得られる２つの飛跡画像を入力し、
%散乱が起こった座標と反跳した${}^{4}\rm{He}$が停止した座標を出力させる。
%%%%学習を効率的に行うために、出力される座標は各軸が0--1の範囲になるように規格化した座標系で得られる。
%%%%このネットワークは２１層からなり、２入力１出力の形をしている。
%教師データには従来手法で決定した座標を用いた。
%学習には3,012 events、評価には1,554 events を使用した。

We used Intel Core i7, Nvidia GeForce GTX 1080Ti, Ubuntu 18.04 LTS, and
TensorFlow~\cite{tensorflow}+Keras~\cite{keras}.
%学習環境はIntel Core i7、Nvidia GeForce GTX 1080Ti、Ubuntu 18.04 LTS、
%TensorFlow~\cite{tensorflow}+Keras~\cite{keras} を用いた。

\section{Result}
\begin{wrapfigure}{r}{25zw}
  \vspace{-6zw}
  \centering
  \includegraphics[clip, width=25zw]{eps/compare_mono.eps}
%  \caption{ニューラルネットワークによって決定した座標とHough変換によって決定した座標との比較}
  \caption{This figure shows comparision of coordinates determined by the conventional method and the neural network.}
  \label{fig:result_detection}
  \vspace{-2zw}
\end{wrapfigure}

The neural network for event selection trained 200 times for 2,700 events.
It took about 26 minutes for training and about 1 second to process for 300 events.
The accuracy evaluated by 300 events that are used for evaluation of the conventional method
is 96\%.
New method is able to select events in higher accuracy than the conventional method.
It takes shorter time to tune parameters and to process than the conventional method.
%事象選別のためのニューラルネットワークは、2,700 events に対して200 回学習を行った。
%学習にはおよそ26分、その後の推測には300 events に対しておよそ1秒かかった。
%従来手法の評価に用いたのと同じ実験データのうち、300 eventsを用いて評価を行った結果、
%正解率は96\%であった。
%従来の手法と比較して高精度に事象選別を行うことが可能となった。
%また、パラメータチューニングおよび選別に要する時間も大きく短縮することができた。

The neural network for track extraction trained 500 times for 3,012 events.
It took about 270 minutes for training and about 2 seconds to process for 1,554 events.
Comparison of coordinates determined by the neural network and the conventional method is shown in Fig. \ref{fig:result_detection}
with a typical image.
The circle point and the triangle point is a scattering point and a stopping point determined by the conventional method.
The square point and the rhombus point is a scattering point and a stopping point determined by the neural network.
The difference between points of conventional method and neural network is about 4 mm in root mean squared error for 1,554 events.
It takes shorter time to tune parameters and process than the conventional method.
%座標の決定のためのニューラルネットワークは、3,012 events に対して500 回学習を行った。
%学習にはおよそ270分、その後の推測には1,554 events に対しておよそ2秒かかった。
%典型的なイベントにおいて、
%学習後にニューラルネットワークが予測した座標と従来手法によって決定した座標の比較をFig. \ref{fig:result_detection} に示す。
%学習データの散乱が起こった点を円、反跳粒子が停止した点を三角で示す。
%学習後に推論によって決定した散乱が起こった点を四角、反跳粒子が停止した点をひし形で示す。
%従来手法とニューラルネットワークを用いた手法のそれぞれで決定した座標は、
%ほぼ一致している。
%1,554 events に対して学習に用いた点とニューラルネットワークを用いて決定した点のズレは、
%平均二乗誤差で約4 mm となった。
%従来の手法と比較してパラメータチューニングおよび情報の抽出にかかる時間を短縮することができた。


\section{Conclusion}
We developed the new method using neural networks replaced the conventional method using Hough transformation.
The new method selects and extracts in high accuracy and processes faster than the conventional method.
Neural networks are useful to analyze data of TPC.
%従来のHough 変換を用いた画像識別アルゴリズムに替わる、
%ニューラルネットワークを用いた新手法の開発を行った。
%新手法は従来のものよりも高速かつ高精度に事象の選別を行うことが可能となった。
%また、飛跡情報の抽出については従来の精度を保ちつつ、高速に行うことが可能となった。
%ニューラルネットワークを用いた解析手法はTPC の解析に有用であることがわかった。

\begin{thebibliography}{9}
\bibitem{mupic}
  A.~Ochi, T.~Nagayoshi, T.~Tanimori, T.~Nagae, and M.~Nakamura,
  Nucl. Instrum. Methods Phys. Res. A \textbf{471}, 264 (2001).
\bibitem{MAIKo}
  T.~Furuno, T.~Kawabata, H.~Ong, S.~Adachi, Y.~Ayyad, T.~Baba, Y.~Fujikawa, T.~Hashimoto, K.~Inaba, Y.~Ishii,
  S.~Kabuki, H.~Kubo, Y.~Matsuda, Y.~Matsuoka, T.~Mizumoto, T.~Morimoto, M.~Murata, T.~Sawano, T.~Suzuki, A.~Takada,
  J.~Tanaka, I.~Tanihata, T.~Tanimori, D.~Tran, M-, Tsumura, and H.~Watanabe,
  Nucl. Instrum. Methods Phys. Res. A \textbf{908}, 215 (2018).
\bibitem{tensorflow}
  A.~Davis, J.~Dean, M.~Devin, S.~Ghemawat, I.~Goodfellow, A.~Harp, G.~Irving,
  M.~Isard, Y.~Jia, R.~Jozefowicz, L.~Kaiser, M.~Kudlur, J.~Levenberg,
  D.~Man\'{e}, R.~Monga, S.~Moore, D.~Murray, C.~Olah, M.~Schuster, J.~Shlens,
  B.~Steiner, I.~Sutskever, K.~Talwar, P.~Tucker, V.~Vanhoucke, V.~Vasudevan,
  F.~Vi\'{e}gas, O.~Vinyals, P.~Warden, M.~Wattenberg, M.~Wicke, Y.~Yu, and
  X.~Zheng, (2015).
  \url{https://tensorflow.org}
\bibitem{keras}
  F.~Chollet, et al., (2015). \url{https://keras.io}
\bibitem{lenet}
  Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner,
  Proceedings of the IEEE \textbf{86}, 11, 2278 (1998).
\bibitem{alexnet}
  Alex~Krizhevsky, Ilya~Sutskever, and Geoffrey~E.~Hinton,
  Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume \textbf{1}, 1097 (2012).
%\bibitem{vgg}
%  K.~Simonyan, and A.~Zisserman
%  arXiv:1409.1556 [cs] (2014).
%
  
%\bibitem{cp} The abbreviation for JPS Conference Proceedings should be ``JPS Conf. Proc." in the reference list.
%\bibitem{jpsj} The abbreviation for the Journal of the Physical Society of Japan should be ``J. Phys. Soc. Jpn." in the reference list.
%\bibitem{ptep} The abbreviation for the Progress of Theoretical and Experimental Physics should be ``Prog. Theor. Exp. Phys." in the reference list.
%\bibitem{instructions} More abbreviations of journal titles are listed in ``Instructions for Preparation of Manuscript", which is available at our Web site (http://jpsj.jps.or.jp).
%\bibitem{format} F. Author, S. Author, and T. Author, Abbreviated journal title \textbf{volume in bold face}, initial page or article number (year of publication).
\end{thebibliography}

\end{document}

